{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "data_path = './hwk2_datasets/'\n",
    "submit_path = './hwk2_submit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification and Nearest Neighbor Classification\n",
    "\n",
    "## 1. Dataset Creation\n",
    "You will use a synthetic data set for the classification task that you’ll generate yourself.\n",
    "Generate two classes with 20 features each. Each class is given by a multivariate Gaussian\n",
    "distribution, with both classes sharing the same covariance matrix. You are provided\n",
    "with the mean vectors (DS1-m0 for mean vector of negative class and DS1-m1 for mean\n",
    "vector of positive class) and the covariance matrix (DS1-cov).\n",
    "\n",
    "Generate 2000 examples for each class, and label the data to be positive if they came\n",
    "from the Gaussian with mean m1 and negative if they came from the Gaussian with\n",
    "mean m0. Randomly pick (without replacement) 20% of each class (i.e., 400 data points\n",
    "per class) as test set, 20% of each class (i.e., 400 data points per class) as validation set\n",
    "set and train the classifiers on the remaining 60% data. When you report performance results, it should be on the test set. Call this dataset as DS1, and submit it with your\n",
    "code. Follow the instructions from Assignment 1 for data submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = pd.read_csv(data_path + 'DS1_m_0.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "m1 = pd.read_csv(data_path + 'DS1_m_1.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "cov = pd.read_csv(data_path + 'DS1_Cov.txt', sep=\",\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data from multivariate Gaussian distribution with mean m0\n",
    "data_0 = pd.DataFrame(data=np.random.multivariate_normal(m0, cov, 2000))\n",
    "data_0.insert(0, 'class', -1)\n",
    "# synthetic data from multivariate Gaussian distribution with mean m1\n",
    "data_1 = pd.DataFrame(data=np.random.multivariate_normal(m1, cov, 2000))\n",
    "data_1.insert(0, 'class', 1)\n",
    "# Create Dataset\n",
    "data_train = pd.concat([data_0.iloc[:400], data_1.iloc[:400]], ignore_index=True)\n",
    "data_valid = pd.concat([data_0.iloc[400:800], data_1.iloc[400:800]], ignore_index=True)\n",
    "data_test = pd.concat([data_0.iloc[800:], data_1.iloc[800:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data into file for submission\n",
    "data_train.to_csv(submit_path + 'Assignment2_1948612_1_1_DS1_train.csv')\n",
    "data_test.to_csv( submit_path + 'Assignment2_1948612_1_1_DS1_test.csv' )\n",
    "data_valid.to_csv(submit_path + 'Assignment2_1948612_1_1_DS1_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GDA Model \n",
    "\n",
    "We first consider the GDA model as seen in class: given the class variable, the data are\n",
    "assumed to be Gaussians with different means for different classes but with the same\n",
    "covariance matrix. This model can formally be specified as follows:\n",
    "Y ∼ Bernoulli(π), X | Y = j ∼ N(μj, Σ).\n",
    "\n",
    "Estimate the parameters of the GDA model using the maximum likelihood approach.\n",
    "\n",
    "(a) For DS1, report the best fit accuracy achieved by the classifier.\n",
    "\n",
    "(b) Report the coefficients learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_GDA_parameters(data_train: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Find the GDA parameters\n",
    "    \"\"\"\n",
    "    # P(y)\n",
    "    phi = data_train['class'].value_counts()[1] / len(data_train['class'])\n",
    "\n",
    "    # μ0 \n",
    "    data_train_0 = data_train.drop(['class'], axis=1).loc[data_train['class'] == -1]\n",
    "    mu_0 = data_train_0.mean()\n",
    "\n",
    "    # μ1\n",
    "    data_train_1 = data_train.drop(['class'], axis=1).loc[data_train['class'] == 1]\n",
    "    mu_1 = data_train_1.mean()\n",
    "\n",
    "    # Covariance \n",
    "    n = len(mu_0)\n",
    "    cov_train = np.zeros((n,n))\n",
    "    for index, row in data_train.iterrows():\n",
    "        if row['class'] == -1:\n",
    "            row = row.drop(['class']) - mu_0\n",
    "        else:\n",
    "            row = row.drop(['class']) - mu_1\n",
    "        x_std = np.asmatrix(row.to_numpy())\n",
    "        cov_train += np.matmul(np.transpose(x_std), x_std)\n",
    "    cov_train = cov_train / len(data_train)\n",
    "    \n",
    "    return phi, mu_0, mu_1, cov_train\n",
    "\n",
    "def eval_px_knowing_y(x, mu, sigma):\n",
    "    # Gaussien\n",
    "    n = len(mu)\n",
    "    det = np.linalg.det(sigma)\n",
    "    denum = np.power((2*np.pi),(n/2)) * np.sqrt(det)\n",
    "    X = np.asmatrix(x-mu)\n",
    "    S = np.linalg.inv(np.asmatrix(sigma))\n",
    "    num = np.exp(-0.5 * np.matmul(np.matmul(X, S),np.transpose(X)).item(0) )\n",
    "    return (num/denum)\n",
    "    \n",
    "def eval_py(y, phi):\n",
    "    return phi if y==1 else (1-phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.567986249923706s seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Find the parameters\n",
    "start_time = time.time()\n",
    "phi, mu_0, mu_1, sigma = find_GDA_parameters(data_train)\n",
    "print(f\"--- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction: True\n"
     ]
    }
   ],
   "source": [
    "# TEST: Try a prediction a single variable\n",
    "x = data_valid.iloc[0].drop(['class']).to_numpy()\n",
    "real_class = data_valid.iloc[0]['class']\n",
    "px_0 = eval_px_knowing_y(x, mu_0, sigma) * eval_py(0, phi)\n",
    "px_1 = eval_px_knowing_y(x, mu_1, sigma) * eval_py(1, phi)\n",
    "guess_class = -1 if px_0 > px_1 else 1\n",
    "print(f\"Good prediction: {True if guess_class == real_class else False}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Accuracy: 94.91666666666667% --- 2.5012707710266113s seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the accuracy\n",
    "start_time = time.time()\n",
    "good_prediction = 0\n",
    "for index, row in data_test.iterrows():\n",
    "    real_class = row['class']\n",
    "    x = row.drop(['class'])\n",
    "    px_0 = eval_px_knowing_y(x, mu_0, sigma) * eval_py(0, phi)\n",
    "    px_1 = eval_px_knowing_y(x, mu_1, sigma) * eval_py(1, phi)\n",
    "    guess_class = -1 if px_0 > px_1 else 1\n",
    "    good_prediction += 1 if guess_class == real_class else 0\n",
    "accuracy = good_prediction / len(data_test)\n",
    "print(f\"a) Accuracy: {accuracy * 100}% --- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the data\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_2_b_phi.txt', np.array([phi]), delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_2_b_mu0.txt', mu_0, delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_2_b_mu1.txt', mu_1, delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_2_b_cov.txt', sigma, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K_NN Model\n",
    "For DS1, use k-NN to learn a classifier. Repeat the experiment for different values of k\n",
    "and report the performance for each value. We will compare this non-linear classifier to\n",
    "the linear approach, and find out how powerful linear classifiers can be.\n",
    "\n",
    "(a) Does this classifier performs better than GDA or worse? Are there particular values\n",
    "of k which perform better? Why does this happen ? Use validation accuracy for\n",
    "model selection.\n",
    "\n",
    "(b) Report the best fit accuracy achieved by this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "class KNN_Classifier:\n",
    "    \n",
    "    def __init__(self, X, y, k=1):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "\n",
    "    def eval(self, x):\n",
    "        h = []\n",
    "        for index in range(len(self.x)):\n",
    "            c = self.y[index]\n",
    "            dist = np.linalg.norm(x - self.x[index])\n",
    "            heapq.heappush(h, (dist, c))\n",
    "        k_nn = []\n",
    "        for _ in range(self.k):\n",
    "            k_nn.append(heapq.heappop(h)[1])\n",
    "        return most_common(k_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=1: 52.0% --- 16.897339344024658s seconds ---\n",
      "Accuracy with k=3: 54.083333333333336% --- 17.181105136871338s seconds ---\n",
      "Accuracy with k=5: 52.87500000000001% --- 16.308059215545654s seconds ---\n",
      "Accuracy with k=9: 54.37499999999999% --- 16.138160705566406s seconds ---\n",
      "Accuracy with k=13: 55.041666666666664% --- 16.134053230285645s seconds ---\n"
     ]
    }
   ],
   "source": [
    "k_lst = [1,3,5,9,13]\n",
    "X = [row.drop(['class']).tolist() for index, row in data_train.iterrows()]\n",
    "y = data_train['class'].tolist()\n",
    "x_test = [np.array(row.drop(['class']).tolist()) for index, row in data_test.iterrows()]\n",
    "y_test = data_test['class'].tolist()\n",
    "\n",
    "for k in k_lst:\n",
    "    k_nn = KNN_Classifier(X, y, k)\n",
    "    start_time = time.time()\n",
    "    r = len(y_test)\n",
    "    good_pred = 0\n",
    "    for i in range(r):\n",
    "        pred = k_nn.eval(x_test[i])\n",
    "        real = y_test[i]\n",
    "        good_pred += 1 if pred == real else 0 \n",
    "    print(f\"Accuracy with k={k}: {(good_pred / r) * 100}% --- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Generated By 3 Gaussians \n",
    "Now instead of having a single multivariate Gaussian distribution per class, each class\n",
    "is going to be generated by a mixture of 3 Gaussians. For each class, we’ll define\n",
    "3 Gaussians, with the first Gaussian of the first class sharing the covariance matrix\n",
    "with the first Gaussian of the second class and so on. For both the classes, fix the\n",
    "mixture probability as (0.1,0.42,0.48) i.e. the sample has arisen from first Gaussian with\n",
    "probability 0.1, second with probability 0.42 and so on. Mean for three Gaussians in the\n",
    "positive class are given as DS2-c1-m1, DS2-c1-m2, DS2-c1-m3. Mean for three Gaussians\n",
    "in the negative class are gives as DS2-c2-m1, DS2-c2-m2, DS2-c2-m3. Corresponding 3\n",
    "covariance matrices are given as DS2-cov-1, DS2-cov-2 and DS2-cov-3. Now sample\n",
    "from this distribution and generate the dataset similar to question 1. Call this dataset\n",
    "as DS2, and submit it with your code. Follow the instructions from Assignment 1 for\n",
    "data submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "DS2_c1_m1 = pd.read_csv(data_path + 'DS2_c1_m1.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "DS2_c1_m2 = pd.read_csv(data_path + 'DS2_c1_m2.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "DS2_c1_m3 = pd.read_csv(data_path + 'DS2_c1_m3.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "DS2_c2_m1 = pd.read_csv(data_path + 'DS2_c2_m1.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "DS2_c2_m2 = pd.read_csv(data_path + 'DS2_c2_m2.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "DS2_c2_m3 = pd.read_csv(data_path + 'DS2_c2_m3.txt', sep=\",\", header=None).to_numpy()[0]\n",
    "\n",
    "DS2_Cov1 = pd.read_csv(data_path + 'DS2_Cov1.txt', sep=\",\", header=None).to_numpy()\n",
    "DS2_Cov2 = pd.read_csv(data_path + 'DS2_Cov2.txt', sep=\",\", header=None).to_numpy()\n",
    "DS2_Cov3 = pd.read_csv(data_path + 'DS2_Cov3.txt', sep=\",\", header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data from 3 multivariate Gaussian distribution with mean m0, m1 and m2\n",
    "data_c1_m1 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c1_m1, DS2_Cov1, int(2000 * 0.1)))\n",
    "data_c1_m2 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c1_m2, DS2_Cov2, int(2000 * 0.42)))\n",
    "data_c1_m3 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c1_m3, DS2_Cov2, int(2000 * 0.48)))\n",
    "data_c1 = pd.concat([data_c1_m1, data_c1_m2, data_c1_m3])\n",
    "data_c1 = data_c1.sample(frac = 1)\n",
    "data_c1.insert(0, 'class', 1)\n",
    "\n",
    "# synthetic data from 3 multivariate Gaussian distribution with mean m1, m1 and m2\n",
    "data_c2_m1 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c2_m1, DS2_Cov1, int(2000 * 0.1)))\n",
    "data_c2_m2 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c2_m2, DS2_Cov2, int(2000 * 0.42)))\n",
    "data_c2_m3 = pd.DataFrame(data=np.random.multivariate_normal(DS2_c2_m3, DS2_Cov2, int(2000 * 0.48)))\n",
    "data_c2 = pd.concat([data_c2_m1, data_c2_m2, data_c2_m3])\n",
    "data_c2 = data_c2.sample(frac = 1)\n",
    "data_c2.insert(0, 'class', -1)\n",
    "\n",
    "# Create Dataset\n",
    "data_c2_train = pd.concat([data_c1.iloc[:400], data_c2.iloc[:400]], ignore_index=True)\n",
    "data_c2_valid = pd.concat([data_c1.iloc[400:800], data_c2.iloc[400:800]], ignore_index=True)\n",
    "data_c2_test = pd.concat([data_c1.iloc[800:], data_c2.iloc[800:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data into file for submission\n",
    "data_c2_train.to_csv(submit_path + 'Assignment2_1948612_1_4_DS2_train.csv')\n",
    "data_c2_test.to_csv( submit_path + 'Assignment2_1948612_1_4_DS2_test.csv' )\n",
    "data_c2_valid.to_csv(submit_path + 'Assignment2_1948612_1_4_DS2_valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model\n",
    "\n",
    "Now perform the experiments in questions 2 and 3 again, but now using DS2.\n",
    "\n",
    "1. Estimate the parameters of the GDA model using the maximum likelihood ap-\n",
    "proach.\n",
    "\n",
    "    (a) For DS2, report the best fit accuracy achieved by the classifier.\n",
    "\n",
    "    (b) Report the coefficients learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.45681095123291016s seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "phi, mu_0, mu_1, sigma = find_GDA_parameters(data_c2_train)\n",
    "print(f\"--- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good prediction: False\n"
     ]
    }
   ],
   "source": [
    "# TEST: Try a prediction\n",
    "x = data_c2_valid.iloc[0].drop(['class']).to_numpy()\n",
    "real_class = data_c2_valid.iloc[0]['class']\n",
    "px_0 = eval_px_knowing_y(x, mu_0, sigma) * eval_py(0, phi)\n",
    "px_1 = eval_px_knowing_y(x, mu_1, sigma) * eval_py(1, phi)\n",
    "guess_class = -1 if px_0 > px_1 else 1\n",
    "print(f\"Good prediction: {True if guess_class == real_class else False}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a) Accuracy: 51.125% --- 2.6442489624023438s seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the accuracy\n",
    "start_time = time.time()\n",
    "good_prediction = 0\n",
    "for index, row in data_c2_test.iterrows():\n",
    "    real_class = row['class']\n",
    "    x = row.drop(['class'])\n",
    "    px_0 = eval_px_knowing_y(x, mu_0, sigma) * eval_py(0, phi)\n",
    "    px_1 = eval_px_knowing_y(x, mu_1, sigma) * eval_py(1, phi)\n",
    "    guess_class = -1 if px_0 > px_1 else 1\n",
    "    good_prediction += 1 if guess_class == real_class else 0\n",
    "accuracy = good_prediction / len(data_c2_test)\n",
    "print(f\"1 a) Accuracy: {accuracy * 100}% --- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the data\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_5_1_b_phi.txt', np.array([phi]), delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_5_1_b_mu0.txt', mu_0, delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_5_1_b_mu1.txt', mu_1, delimiter=',')\n",
    "np.savetxt(submit_path + 'Assignment2_1948612_1_5_1_b_cov.txt', sigma, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Does k-NN classifier perform better than GDA or worse? Are there particular\n",
    "values of k which perform better? Why does this happen ?\n",
    "\n",
    "\n",
    "3. Report the best fit accuracy achieved by this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=1: 49.125% --- 16.059664726257324s seconds ---\n",
      "Accuracy with k=3: 49.25% --- 16.311174869537354s seconds ---\n",
      "Accuracy with k=5: 51.916666666666664% --- 16.200719118118286s seconds ---\n",
      "Accuracy with k=9: 51.33333333333333% --- 15.901687145233154s seconds ---\n",
      "Accuracy with k=13: 51.37500000000001% --- 16.707412004470825s seconds ---\n"
     ]
    }
   ],
   "source": [
    "k_lst = [1,3,5,9,13]\n",
    "X = [row.drop(['class']).tolist() for index, row in data_c2_train.iterrows()]\n",
    "y = data_c2_train['class'].tolist()\n",
    "x_test = [np.array(row.drop(['class']).tolist()) for index, row in data_c2_test.iterrows()]\n",
    "y_test = data_c2_test['class'].tolist()\n",
    "\n",
    "for k in k_lst:\n",
    "    k_nn = KNN_Classifier(X, y, k)\n",
    "    start_time = time.time()\n",
    "    r = len(y_test)\n",
    "    good_pred = 0\n",
    "    for i in range(r):\n",
    "        pred = k_nn.eval(x_test[i])\n",
    "        real = y_test[i]\n",
    "        good_pred += 1 if pred == real else 0 \n",
    "    print(f\"Accuracy with k={k}: {(good_pred / r) * 100}% --- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MNIST Handwritting Digits Classification\n",
    "\n",
    "In this section, we will use the MNIST handwritten digits classification dataset. The task\n",
    "is to classify a given image of a handwritten digit into one of 10 classes representing integer\n",
    "values from 0 to 9, inclusively. The dataset consists of 60,000 training data points and\n",
    "10,000 test data points. The datapoints are represented as 28×28 pixel grayscale images of\n",
    "handwritten single digits between 0 and 9.\n",
    "\n",
    "To load the dataset, using the following code. However, remember that for any other implementation you should not use tensorflow/sklearn/keras as mentioned in the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras\n",
    "from tensorflow import keras\n",
    "# Loading the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first 50,000 examples in (x train, y train) as your training data and use the last\n",
    "10,000 examples in (x train, y train) as your validation data. The examples are represented\n",
    "as pixel matrices of size (28,28). You should first flatten the image matrix to 784 features\n",
    "before passing it to the classifiers. The pixel values are in the range of (0,255). You should\n",
    "normalize the features by dividing them by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_normalize_images(image_arr: np.array):\n",
    "    flatten_images = []\n",
    "    for i in range(len(image_arr)):\n",
    "        flatten_images.append(image_arr[i].flatten()/255)\n",
    "    return np.array(flatten_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = flat_normalize_images(x_train[50000:60000])\n",
    "y_valid = y_train[50000:60000]\n",
    "x_train = flat_normalize_images(x_train[:50000])\n",
    "y_train = y_train[:50000]\n",
    "x_test = flat_normalize_images(x_test) \n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    0    1    2    3    4    5    6    7    8  ...  774  775  776  \\\n",
       "0      5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "   777  778  779  780  781  782  783  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "df_train = pd.DataFrame(data=x_train)\n",
    "df_train.insert(0, 'class', y_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gaussian Naïve Bayes (GNB) \n",
    "First we will consider Gaussian Na ̈ıve Bayes (GNB) model for this task. This is same as\n",
    "the GDA model from the previous question but with two modifications: The covariance\n",
    "matrices are not shared and they are diagonal (Na ̈ıve Bayes assumption).\n",
    "\n",
    "(a) Write down the equations for computing the mean and diagonal covariance matrices\n",
    "for the class conditional densities and also the prior class probabilities using the\n",
    "maximum likelihood approach.\n",
    "\n",
    "(b) Estimate the parameters of the GNB model from the dataset. Report the best fit\n",
    "accuracy achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_GNB_params(data: pd.DataFrame, lsc: int=0):\n",
    "    \"\"\"\n",
    "    Find the parameters of Gaussian Naïve Bayes\n",
    "    @params:\n",
    "        - Data\n",
    "        - lsc: Laplace smoothing coeffience\n",
    "    \"\"\"\n",
    "    # P(y)\n",
    "    phi = data['class'].value_counts() / len(data)\n",
    "    \n",
    "    # μ and variance\n",
    "    mu = {}\n",
    "    variance = {}\n",
    "    n = data['class'].value_counts()\n",
    "\n",
    "    for c in range(0,10):\n",
    "        features = data.loc[data['class'] == c].drop(['class'], axis=1)\n",
    "        \n",
    "        # Means\n",
    "        n_feature = features.shape[1]\n",
    "        n_occ_c = features.shape[0]\n",
    "        features_mean = (np.sum(features, axis=0) + lsc) / (n_occ_c + lsc * n_feature) \n",
    "        mu[c] = features_mean\n",
    "        \n",
    "        # Variance\n",
    "        s_2 = np.zeros(n[c], n[c])\n",
    "        sum_of_error_2 = features.sub(features_mean).pow(2).sum()\n",
    "        variances_arr = sum_of_error_2 / (n[c] - 1)\n",
    "        variance[c] = np.diag(np.sqrt(variances_arr))\n",
    "        \n",
    "    return phi, mu, variance\n",
    "\n",
    "def compute_wk(sigma_inv, mu):\n",
    "    return np.matmul(sigma_inv, mu)\n",
    "\n",
    "def compute_w0(sigma_inv, mu, pc):\n",
    "    return (-0.5) * np.transpose(mu) @ sigma_inv @ mu + np.log(pc)\n",
    "\n",
    "def compute_ak(x, mu, sigma, pc):\n",
    "    mu = np.transpose(mu)\n",
    "    inv = np.linalg.inv(np.asmatrix(sigma))\n",
    "    wk = compute_wk(inv, mu)\n",
    "    w0 = compute_w0(inv, mu, pc)\n",
    "    return np.transpose(wk) @ x + w0\n",
    "                     \n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.3728649616241455s seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "phi, mu, sigma = find_GNB_params(df_train, 0.5)\n",
    "print(f\"--- {(time.time() - start_time)}s seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 9 | real: 9\n"
     ]
    }
   ],
   "source": [
    "i = 1099\n",
    "x = x_valid[i]\n",
    "y = y_valid[i]\n",
    "\n",
    "ak = [compute_ak(x, mu[c], sigma[c], 0.1) for c in range(10)]\n",
    "sm = softmax(np.array(ak))\n",
    "pred = np.argmax(sm)\n",
    "        \n",
    "print(f\"pred: {pred} | real: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Accuracy: 80.58% --- 1911.9195761680603s seconds ---\n"
     ]
    }
   ],
   "source": [
    "good_prediction = 0\n",
    "n = x_valid.shape[0]\n",
    "# n = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(n):\n",
    "    # Features and \n",
    "    x = x_valid[i]\n",
    "    y = y_valid[i]\n",
    "    \n",
    "    ak = [compute_ak(x, mu[c], sigma[c], 0.1) for c in range(10)]\n",
    "    sm = softmax(np.array(ak))\n",
    "    pred = np.argmax(sm)\n",
    "\n",
    "    good_prediction += 1 if pred == y else 0\n",
    "\n",
    "accuracy = good_prediction / n\n",
    "print(f\"a) Accuracy: {accuracy * 100}% --- {(time.time() - start_time)}s seconds ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-NN\n",
    "Use k-NN to learn a classifier. Repeat the experiment for different values of k and report\n",
    "the performance for each value.\n",
    "\n",
    "(a) Are there particular values of k which perform better? Why does this happen ? Use validation accuracy for model selection.\n",
    "\n",
    "(b) Report the best fit accuracy achieved by this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "class KNN_Classifier:\n",
    "    \n",
    "    def __init__(self, X, y, k=1):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        self.k = k\n",
    "\n",
    "    def eval(self, x):\n",
    "        h = []\n",
    "        for index in range(len(self.x)):\n",
    "            c = self.y[index]\n",
    "            dist = np.linalg.norm(x - self.x[index])\n",
    "            heapq.heappush(h, (dist, c))\n",
    "        k_nn = []\n",
    "        for _ in range(self.k):\n",
    "            k_nn.append(heapq.heappop(h)[1])\n",
    "        return most_common(k_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=1: 96.2% --- 202.660737991333s seconds ---\n",
      "Accuracy with k=10: 96.0% --- 204.27352786064148s seconds ---\n",
      "Accuracy with k=12: 96.0% --- 200.88634586334229s seconds ---\n",
      "Accuracy with k=15: 96.0% --- 196.36129307746887s seconds ---\n",
      "Accuracy with k=21: 95.8% --- 192.36278986930847s seconds ---\n",
      "Accuracy with k=35: 94.6% --- 184.72234272956848s seconds ---\n"
     ]
    }
   ],
   "source": [
    "k_lst = [1,10,12,15,21,35]\n",
    "for k in k_lst:\n",
    "    k_nn = KNN_Classifier(x_train, y_train, k)\n",
    "    start_time = time.time()\n",
    "    r = 500\n",
    "    good_pred = 0\n",
    "    for i in range(r):\n",
    "        pred = k_nn.eval(x_test[i])\n",
    "        real = y_test[i]\n",
    "        good_pred += 1 if pred == real else 0 \n",
    "    print(f\"Accuracy with k={k}: {(good_pred / r) * 100}% --- {(time.time() - start_time)}s seconds ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation with sklearn k_nn algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "good_pred = 0\n",
    "for i in range(len(x_test)):\n",
    "    pred = neigh.predict([x_test[i]])[0]\n",
    "    real = y_test[i]\n",
    "    good_pred += 1 if pred == real else 0\n",
    "print(f\"Accuracy: {(good_pred / r)*100}% --- {(time.time() - start_time)}s seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
